{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "50748985-76bc-45b4-a0e0-0c09a5def870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Apriori\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6bea81e-4efd-4010-89c8-48e2a7d6d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile('../data/msnbc/data50k.csv') \\\n",
    "         .map(lambda line: list(map(int,line.split(',')))) \\\n",
    "         .zipWithIndex() \\\n",
    "         .map(lambda x: (x[1], x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c1ca3815-30ec-4922-98bc-b0dbe5e08e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sortByKey().saveAsTextFile(\"./dataset\")\n",
    "\n",
    "dataset = []\n",
    "for file in glob.glob(\"./dataset/part-*\"):\n",
    "    for line in open(file, \"r\").readlines():\n",
    "        line = eval(line)\n",
    "        dataset.append(line)\n",
    "\n",
    "shutil.rmtree(\"./dataset\")\n",
    "\n",
    "dataset = sc.broadcast(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dcdcd085-af02-4e91-844e-e1542b6edabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1, [2])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.value[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2bddb633-5775-4573-9587-68b7debecfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1cdb6dbd-4fb4-4b94-975e-d3f4b2c99955",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(\"../data/msnbc/data.csv\", 'r').readlines()[:100000]\n",
    "open(\"../data/msnbc/data50k.csv\", 'w').writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a48a65-df3b-4ef5-ab42-1a5eca6b4bdc",
   "metadata": {},
   "source": [
    "## getMinSupItems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de7553-8a80-41ad-b6dc-13200ad095c9",
   "metadata": {},
   "source": [
    "### itemlocmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0f79cd59-0cdf-4210-8803-4e4e0382a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices_for(x):\n",
    "    key = x[0]\n",
    "    seq_id = x[1]\n",
    "    id, seq = dataset.value[seq_id]\n",
    "    indices = []\n",
    "    for idx in range(len(seq)):\n",
    "        if seq[idx] == key:\n",
    "            indices.append(idx)\n",
    "    return key, seq_id, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70141c19-c92e-4c21-946d-e28f9ad18296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_last_index(x):\n",
    "    key = x[0]\n",
    "    seq_id = x[1]\n",
    "    indices = x[2]\n",
    "    return key, (seq_id, indices[0], indices[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f6b1e643-586a-4895-9727-bf02cde19f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(x):\n",
    "    key = x[0]\n",
    "    sequences = x[1]\n",
    "    freq = len(sequences)\n",
    "    return key, freq, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a8f5ab58-20ae-46e9-9dd7-458beef5a4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "itemlocmap = data.map(lambda x: (x[0], set(x[1])))  \\\n",
    "        .flatMapValues(lambda x:x) \\\n",
    "        .map(lambda x: (x[1], x[0])) \\\n",
    "        .map(lambda x: get_first_last_index(get_indices_for(x))) \\\n",
    "        .groupByKey() \\\n",
    "        .mapValues(list) \\\n",
    "        .map(get_freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3d59f-8649-471c-9d94-b8a081a4abab",
   "metadata": {},
   "source": [
    "### above_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4a9fd58c-78d1-42de-aba5-d7e22cae2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "305e52c4-5e2d-4507-9dfc-77918ae1a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def above_threshold_filter(x, threshold=THRESHOLD):\n",
    "    return x[1] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "47def428-2ede-41a3-916d-16e984448ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "above_threshold = itemlocmap.filter(lambda x: above_threshold_filter(x, THRESHOLD)) \\\n",
    "                            .map(lambda x: (x[0], (x[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "de997a7a-4a1c-4897-aa14-e9542bf780c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "above_threshold.\\\n",
    "    sortByKey().\\\n",
    "    saveAsTextFile(\"./above_threshold\")\n",
    "\n",
    "\n",
    "items = []\n",
    "for file in glob.glob(\"./above_threshold/part-*\"):\n",
    "    for line in open(file, \"r\").readlines():\n",
    "        line = eval(line)\n",
    "        items.append(line)\n",
    "\n",
    "\n",
    "shutil.rmtree(\"./above_threshold\")\n",
    "\n",
    "items = sc.broadcast(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4ef7abb7-c130-4349-8a72-28248a68a27f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# items.value[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8412e6d2-0775-4919-ab9c-f43910f07cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_seq(x):\n",
    "    item, (freq, seq) = x\n",
    "    return item, [y[0] for y in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d201871d-c86d-49b1-a823-7513ad34e72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "above_threshold.\\\n",
    "    map(extract_seq).\\\n",
    "    sortByKey().\\\n",
    "    saveAsTextFile(\"./item_sequences\")\n",
    "\n",
    "item_sequences = []\n",
    "\n",
    "for file in glob.glob(\"./item_sequences/part-*\"):\n",
    "    for line in open(file, \"r\").readlines():\n",
    "        line = eval(line)\n",
    "        item_sequences.append(line)\n",
    "\n",
    "shutil.rmtree(\"./item_sequences\")\n",
    "item_sequences = sc.broadcast(item_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8410caad-3945-4768-b49c-bfe01990be4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# item_sequences.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "008b8323-a108-459d-9bab-fcee41c6ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "above_threshold.\\\n",
    "    map(lambda x:x[0]).\\\n",
    "    sortBy(lambda x:x).\\\n",
    "    saveAsTextFile(\"./items_ids_above_threshold\")\n",
    "\n",
    "items_ids_above_threshold = []\n",
    "for file in glob.glob(\"./items_ids_above_threshold/part-*\"):\n",
    "    for line in open(file, \"r\").readlines():\n",
    "        line = eval(line)\n",
    "        items_ids_above_threshold.append(line)\n",
    "\n",
    "shutil.rmtree(\"./items_ids_above_threshold\")\n",
    "items_ids_above_threshold = sc.broadcast(items_ids_above_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "389fdd35-d544-4ad6-ad33-74fce531fb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_ids_above_threshold.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b30ab-6ae3-4b97-b85a-9ed52d49e30f",
   "metadata": {},
   "source": [
    "## genRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "74bd2b2b-aaa7-4708-95e5-079a07410b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ids = above_threshold.map(lambda x: x[0]) \\\n",
    "                           .zipWithIndex()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "57fd165a-77f8-49ce-8776-a917efb2442e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_items = items_ids.count()\n",
    "count_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44b333-7816-4b97-a62b-ed81d0eed369",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "53da82e7-c274-48cf-9932-49002f41dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_join(x, count):\n",
    "    return x, tuple(range(x[1] + 1, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a1f9e1f6-5406-4638-b806-91da332b3b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_join = items_ids.map(lambda x: prepare_join(x, count_items)) \\\n",
    "                      .flatMapValues(lambda x:x) \\\n",
    "                      .map(lambda x: (x[0][1], x[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02cf75-24a0-4062-b085-9c5c3f1bba37",
   "metadata": {},
   "source": [
    "### I => J combination with no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "195d3a83-624d-43c7-8fd5-f33fef59b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_common_sequences(x):\n",
    "    i = x[0]\n",
    "    j = x[1]\n",
    "    itemI, itemJ = items.value[i], items.value[j]\n",
    "    occurancesI, occurancesJ = itemI[1][1], itemJ[1][1]\n",
    "\n",
    "    allseqboth = []\n",
    "\n",
    "    # Old\n",
    "    # for seq_idI, firstI, lastI in occurancesI:\n",
    "    #     for seq_idJ, firstJ, lastJ in occurancesJ:\n",
    "    #         if seq_idI == seq_idJ:\n",
    "    #             allseqboth.append((seq_idI, (firstI, lastI), (firstJ, lastJ)))\n",
    "\n",
    "    # New\n",
    "    dictI = dict()\n",
    "    for seq_idI, firstI, lastI in occurancesI:\n",
    "        dictI[seq_idI] = (firstI, lastI)\n",
    "    for seq_idJ, firstJ, lastJ in occurancesJ:\n",
    "        if seq_idJ in dictI:\n",
    "            allseqboth.append((seq_idJ, dictI[seq_idJ], (firstJ, lastJ)))\n",
    "\n",
    "    return x, allseqboth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a76714d6-eaa1-4f51-9eea-6e9037cbef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_IJ_JI_rules(x):\n",
    "    key = x[0]\n",
    "    seq_id, itemI, itemJ = x[1]\n",
    "\n",
    "    IJ = []\n",
    "    JI = []\n",
    "    if itemI[0] < itemJ[1]:\n",
    "        IJ.append(seq_id)\n",
    "    if itemJ[0] < itemI[1]:\n",
    "        JI.append(seq_id)\n",
    "\n",
    "    return key, [IJ, JI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "233a775e-49a4-42fd-b8e1-0eff1d5df2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_IJ_JI_rules(a, b):\n",
    "    a[0] += b[0]\n",
    "    a[1] += b[1]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3c274674-eb73-493d-a986-a652fa659b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_index_info(x):\n",
    "    key = x[0]\n",
    "    valuesI, valuesJ = x[1]\n",
    "    return key, ((valuesI, key), (valuesJ, tuple(reversed(key))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7669309f-75c7-4b8d-a0b9-52fb3ef28fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_IJ_JI = items_join.map(prepare_common_sequences) \\\n",
    "                    .flatMapValues(lambda x:x) \\\n",
    "                    .map(count_IJ_JI_rules) \\\n",
    "                    .reduceByKey(group_IJ_JI_rules) \\\n",
    "                    .map(add_index_info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34357e1b-eb8f-4331-90a7-f1855d9a4d09",
   "metadata": {},
   "source": [
    "### Accumulate rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "69283b16-3674-406e-baef-cf68e5809576",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SUP_REL = 0.01 * len(dataset.value)\n",
    "MIN_CONF = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a4dd7eb-0a42-4235-9fe3-ad2ab28bef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq(x):\n",
    "    key = x[0]\n",
    "    values = x[1]\n",
    "    frequencies = len(values)\n",
    "    return key, (values, frequencies)\n",
    "\n",
    "def is_above_minsup_relative(x, minsup_relative):\n",
    "    return x[1][1] > minsup_relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "aa73d1d8-6979-467a-87c2-2d42ac9f9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rule_and_expands(x, min_conf=MIN_CONF):\n",
    "    # Try to optimize\n",
    "    i, j = x[0]\n",
    "    allseqIJ, length = x[1]\n",
    "    itemI, itemJ = items.value[i], items.value[j]\n",
    "    occurancesI, occurancesJ = itemI[1][1], itemJ[1][1]\n",
    "#     occurancesI = (seq_id, first, last)\n",
    "\n",
    "    allseqI = [x[0] for x in occurancesI]\n",
    "    allseqJ = [x[0] for x in occurancesJ]\n",
    "\n",
    "    confIJ = length / len(occurancesI)\n",
    "\n",
    "    antecedentSet = set([i])\n",
    "    consequentSet = set([j])\n",
    "\n",
    "    rules = []\n",
    "    if confIJ >= min_conf:\n",
    "        rules.append((antecedentSet, consequentSet, length / len(dataset.value), confIJ))\n",
    "\n",
    "#     expandLeft(antecedentSet,consequentSet,allseqI,allseqIJ,occurancesJ)\n",
    "#     expandRight(antecedentSet,consequentSet,allseqI,allseqJ,allseqIJ,occurancesI,occurancesJ)\n",
    "\n",
    "    expand_left = (0, antecedentSet, consequentSet, allseqI, occurancesJ, allseqIJ)\n",
    "    expand_right = (1, antecedentSet, consequentSet, allseqI, allseqJ, occurancesI, occurancesJ, allseqIJ)\n",
    "    return rules, expand_left, expand_right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1e84e-fe5d-4b99-bcd5-3696cf94654d",
   "metadata": {},
   "source": [
    "## Expand Left - Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fe7418e0-0f49-4c8f-ba21-a255ba112a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(x, min_sup_rel=MIN_SUP_REL, min_conf=MIN_CONF):\n",
    "    if x[0] == 0:\n",
    "        return expand_left(x[1:], min_sup_rel, min_conf)\n",
    "    else:\n",
    "        return expand_right(x[1:], min_sup_rel, min_conf)\n",
    "\n",
    "\n",
    "def item_suitable_for_antecedentSet(item, index_item, antecedentSet, consequentSet):\n",
    "    for i in antecedentSet:\n",
    "        if i >= index_item:\n",
    "            return False\n",
    "    if index_item in consequentSet or item not in items_ids_above_threshold.value:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "68d2c925-2fa0-40b7-bc76-eb4b7ddd0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_of_item(item):\n",
    "    for i, j in enumerate(items_ids_above_threshold.value):\n",
    "        if j == item:\n",
    "            return i\n",
    "    return len(items_ids_above_threshold.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4aa47d48-a301-43e3-8ba5-92dee13307d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_last(occurances, seq_id):\n",
    "    for id, first, last in occurances:\n",
    "        if id == seq_id:\n",
    "            return first, last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b174d5b8-4ce4-4432-8cb6-33753273278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_left(x, min_sup_rel, min_conf):\n",
    "    # Try to optimize\n",
    "    antecedentSet, consequentSet, allseqI, occurancesJ, allseqIJ = x\n",
    "\n",
    "    possibleC = dict()\n",
    "    rules = []\n",
    "    expand_lefts = []\n",
    "    seqsLeft = len(allseqIJ)\n",
    "\n",
    "    for seqID in allseqIJ:\n",
    "        _, seq = dataset.value[seqID] # Get sequence\n",
    "        firstJ, lastJ = find_first_last(occurancesJ, seqID) # Get last occurance of J in sequene\n",
    "\n",
    "        for item in seq[:lastJ]:\n",
    "            index_item = index_of_item(item)\n",
    "            if not item_suitable_for_antecedentSet(item, index_item, antecedentSet, consequentSet):\n",
    "                continue\n",
    "\n",
    "            if index_item not in possibleC: # first time item was found\n",
    "                if seqsLeft >= min_sup_rel: # min_sup_rel can be accomplished\n",
    "                    possibleC[index_item] = set([seqID])\n",
    "            elif len(possibleC[index_item]) + seqsLeft < min_sup_rel: # there no enough seqLeft to accomplish min_sup\n",
    "                del possibleC[index_item]\n",
    "            else:\n",
    "                possibleC[index_item].add(seqID)\n",
    "\n",
    "        seqsLeft -= 1\n",
    "\n",
    "    # Loop through possibleC to generate valid rules\n",
    "    for itemC, seqIDs in possibleC.items():\n",
    "        # Check if minimum support requirement is met\n",
    "        if len(seqIDs) >= min_sup_rel:\n",
    "            # SeqIDs of IuC \n",
    "            item, seqC = item_sequences.value[itemC]\n",
    "            allseqIC = set.intersection(set(seqC),allseqI)\n",
    "\n",
    "            confIC_J = len(seqIDs) / len(allseqIC)\n",
    "\n",
    "            itemsIC = antecedentSet.copy()\n",
    "            itemsIC.add(itemC)\n",
    "\n",
    "            if confIC_J >= min_conf:\n",
    "                rules.append((itemsIC,consequentSet,len(seqIDs)/len(dataset.value),confIC_J))\n",
    "\n",
    "            expand_lefts.append((0, itemsIC,consequentSet, allseqIC, occurancesJ, seqIDs))\n",
    "    return rules, expand_lefts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a4159e4a-f615-47db-a86a-904f43c8e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_right(x, min_sup_rel, min_conf):\n",
    "    antecedentSet, consequentSet, allseqI, allseqJ, occurancesI, occurancesJ, allseqIJ = x\n",
    "\n",
    "    possibleC = dict()\n",
    "    rules = []\n",
    "    expand_lefts = []\n",
    "    expand_rights = []\n",
    "    seqsLeft = len(allseqIJ)\n",
    "\n",
    "    for seqID in allseqIJ:\n",
    "        _, seq = dataset.value[seqID] # Get sequence\n",
    "        firstI, lastI = find_first_last(occurancesI, seqID) # Get last occurance of J in sequene\n",
    "\n",
    "        for item in seq[firstI+1:]:\n",
    "            index_item = index_of_item(item)\n",
    "            if not item_suitable_for_antecedentSet(item, index_item, consequentSet, antecedentSet):\n",
    "                continue\n",
    "            if index_item not in possibleC: # first time item was found\n",
    "                if seqsLeft >= min_sup_rel: # min_sup_rel can be accomplished\n",
    "                    possibleC[index_item] = set([seqID])\n",
    "            elif len(possibleC[index_item]) + seqsLeft < min_sup_rel: # there no enough seqLeft to accomplish min_sup\n",
    "                del possibleC[index_item]\n",
    "            else:\n",
    "                possibleC[index_item].add(seqID)\n",
    "\n",
    "        seqsLeft -= 1\n",
    "\n",
    "    for itemC, seqIDs in possibleC.items():\n",
    "        if len(seqIDs) >= min_sup_rel:\n",
    "\n",
    "            allseqJC = set()\n",
    "            # New consequent occurance map\n",
    "            occurancesJC = dict()\n",
    "\n",
    "            for seqID_J in allseqJ:\n",
    "                item, seqC = item_sequences.value[itemC]\n",
    "                if seqID_J in seqC:\n",
    "                    firstC, lastC = find_first_last(items.value[itemC][1][1], seqID_J)\n",
    "                    allseqJC.add(seqID_J)\n",
    "                    firstJ, lastJ = find_first_last(occurancesJ,seqID_J)\n",
    "                    if lastC < lastJ:\n",
    "                        occurancesJC[seqID_J] = [seqID_J,firstC,lastC]\n",
    "                    else:\n",
    "                        occurancesJC[seqID_J] = [seqID_J,firstJ,lastJ]\n",
    "\n",
    "            occurancesJC = list(occurancesJC.values())\n",
    "            confI_JC = len(seqIDs) / len(allseqI)\n",
    "            itemsJC = consequentSet.copy()\n",
    "            itemsJC.add(itemC)\n",
    "\n",
    "            if confI_JC >= min_conf:\n",
    "                rules.append((antecedentSet,itemsJC,len(seqIDs)/len(dataset.value),confI_JC))\n",
    "\n",
    "            expand_lefts.append((0, antecedentSet, itemsJC, allseqI,occurancesJC, seqIDs))\n",
    "            expand_rights.append((1, antecedentSet, itemsJC, allseqI, allseqJC, occurancesI, occurancesJC, seqIDs))\n",
    "\n",
    "    return rules,  expand_rights + expand_lefts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ec839153-7bde-4540-9888-9a294a364822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99b261db-0324-4c44-acac-8ea9bac742a4",
   "metadata": {},
   "source": [
    "## Compute Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6c3d645d-bb40-4070-9238-c4bec1c99854",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SUP_REL = 0.01 * len(dataset.value)\n",
    "MIN_CONF = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "caaab45b-50a7-4554-8cce-c6c0ac46cb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "47"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_and_expands = reduced_IJ_JI.flatMapValues(lambda x:x) \\\n",
    "                     .map(lambda x: (x[1][1], x[1][0])) \\\n",
    "                     .map(get_freq) \\\n",
    "                     .filter(lambda x: is_above_minsup_relative(x, MIN_SUP_REL)) \\\n",
    "                     .map(lambda x: generate_rule_and_expands(x, MIN_CONF))\n",
    "rules_and_expands.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5989a5e8-c86b-4134-ad0d-4cc3c12bb576",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules_and_expands.map(lambda x: x[0]) \\\n",
    "                         .filter(lambda x: len(x) > 0) \\\n",
    "                         .saveAsTextFile(\"./rules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "expands = rules_and_expands.map(lambda x: (x[1], x[2])) \\\n",
    "                           .flatMap(lambda x: x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "rules = []\n",
    "\n",
    "def read_rules():\n",
    "    if not os.path.isdir('./rules'):\n",
    "        print(\"Not dir\")\n",
    "        return\n",
    "    global rules\n",
    "    lines = []\n",
    "    for file in glob.glob('./rules/part-*'):\n",
    "        lines += open(file, \"r\").readlines()\n",
    "    for line in lines:\n",
    "        line = eval(line)\n",
    "        for rule in line:\n",
    "            rules.append(rule)\n",
    "    shutil.rmtree(\"./rules\")\n",
    "\n",
    "read_rules()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "88216b07-a8a4-4bf5-8120-66707770370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 rules\n"
     ]
    }
   ],
   "source": [
    "print(f'Found {len(rules)} rules')\n",
    "# print(len(expands.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0ae1ae92-4faa-47ed-a8c0-7d1fdc030ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 rules\n",
      "Time: 82.66924667358398\n",
      "Found 35 rules\n",
      "Time: 170.87187314033508\n",
      "Time: 256.5634446144104\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "while True:\n",
    "    rules_and_expands = expands.map(lambda x: expand(x, MIN_SUP_REL, MIN_CONF))\n",
    "    rules_and_expands.map(lambda x: x[0]) \\\n",
    "                          .filter(lambda x: len(x) > 0) \\\n",
    "                          .saveAsTextFile(\"./rules\")\n",
    "    expands = rules_and_expands.map(lambda x: x[1]) \\\n",
    "                           .filter(lambda x: len(x) > 0) \\\n",
    "                           .flatMap(lambda x: x)\n",
    "    read_rules()\n",
    "    print(f'Found {len(rules)} rules')\n",
    "    print(\"Time:\", time.time() - start)\n",
    "    if expands.isEmpty():\n",
    "        break\n",
    "\n",
    "print(\"Time:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4c3a850c-8dab-4ebf-b389-345b68043a21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[({0}, {1}, 0.07204, 0.22549142356329036),\n ({1}, {0}, 0.04277, 0.23892519970951343),\n ({2}, {0}, 0.01895, 0.15461814621409922),\n ({0}, {3}, 0.03697, 0.11571929385251033),\n ({3}, {0}, 0.0235, 0.19019100032372938),\n ({0}, {5}, 0.0362, 0.11330912733191437),\n ({0}, {6}, 0.03488, 0.10917741329660699),\n ({6}, {0}, 0.02606, 0.3220862686936102),\n ({8}, {0}, 0.01046, 0.11636444543330737),\n ({9}, {0}, 0.0141, 0.27920792079207923),\n ({10}, {0}, 0.02234, 0.3841127922971114),\n ({0}, {11}, 0.04127, 0.12917866533116315),\n ({11}, {0}, 0.02591, 0.23055703861897134),\n ({0}, {13}, 0.0379, 0.11863027419556779),\n ({13}, {0}, 0.02294, 0.19275691118393412),\n ({2}, {1}, 0.01416, 0.11553524804177545),\n ({1}, {3}, 0.0199, 0.11116697391207195),\n ({3}, {1}, 0.01733, 0.14025574619618),\n ({6}, {1}, 0.01215, 0.15016685205784205),\n ({9}, {1}, 0.01127, 0.22316831683168317),\n ({10}, {1}, 0.01211, 0.20821870701513068),\n ({11}, {1}, 0.01483, 0.13196298273714185),\n ({3}, {6}, 0.01789, 0.14478795726772417),\n ({6}, {3}, 0.02384, 0.2946483747373625),\n ({8}, {3}, 0.01443, 0.16052953609967738),\n ({5}, {6}, 0.0295, 0.1347647327546825),\n ({6}, {5}, 0.02416, 0.29860338647880363),\n ({8}, {6}, 0.01161, 0.12915785960618534),\n ({12}, {13}, 0.01611, 0.21197368421052631),\n ({0, 3}, {1}, 0.01025, 0.2569566307345199),\n ({0, 5}, {1}, 0.01002, 0.24355858045697618),\n ({0, 1}, {3}, 0.01179, 0.15674022866258974),\n ({0, 6}, {3}, 0.01266, 0.3383217530732229),\n ({0, 1}, {5}, 0.01073, 0.14264823185323053),\n ({0, 1}, {11}, 0.01021, 0.13573517681467695)]"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"all_rules.txt\", \"w\").write(str(rules))\n",
    "rules\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}